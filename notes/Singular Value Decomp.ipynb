{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therorem:** Suppose $A \\in R^{n \\times m}$ and $n \\geq m$. Then $\\exists U \\in R^{n\\times n}$ and $\\exists V \\in R^{m\\times m}$ orthogonal and there is a diagonal matrix $\\Sigma =   \\begin{pmatrix}\n",
    "    \\sigma_{1} & & \\\\\n",
    "    & \\ddots & \\\\\n",
    "    & & \\sigma_{m} \\\\\n",
    "    0 &\\cdots &0 \\\\\n",
    "    \\vdots &\\vdots &\\vdots \\\\\n",
    "    0 &\\cdots &0\n",
    "  \\end{pmatrix}$ where $\\sigma_1, \\cdots, \\sigma_m$ are $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\sigma_m \\geq 0$. S.T.\n",
    "  \n",
    "  $$A  = U \\Sigma V^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Singular Linear System\n",
    "One of the strengths of the SVD is that it works when the matrix is singular.\n",
    "\n",
    "Solve the following singular system\n",
    "\n",
    "$$Ay = b, A\\in R^{n \\times m}, rank(A) < m \\leq n$$\n",
    "\n",
    "By using SVD, we get $A = U\\Sigma V^T$, then $U\\Sigma V^Ty = b$. Let $V^Ty = z$ and $U^Tb = c$. We get:$\\Sigma z = c$.\n",
    "i.e:\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "    \\sigma_{1} & & & &\\\\\n",
    "    & \\ddots & & &\\\\\n",
    "    & & \\sigma_{r} & &\\\\\n",
    "    & & & 0 & \\\\\n",
    "    & & & & \\ddots \\\\\n",
    "    & & & & & 0 \\\\\n",
    "    0 & &\\cdots& & &0 \\\\\n",
    "    \\vdots & &\\vdots & & &\\vdots \\\\\n",
    "    0 & &\\cdots & & &0\n",
    "  \\end{pmatrix}  \\begin{pmatrix} Z_1 \\in R^r \\\\ Z_2 \\in R^{n - r} \\end{pmatrix} = \\begin{pmatrix} c_1 \\\\ 0 \\end{pmatrix}$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\implies Z_1 = \\begin{pmatrix}\n",
    "    \\sigma_{1}^{-1} & & \\\\\n",
    "    & \\ddots & \\\\\n",
    "    & & \\sigma_{r}^{-1} \\\\\n",
    "  \\end{pmatrix} c_1$$\n",
    "  \n",
    "Thus,\n",
    "\n",
    "$$y = \\begin{pmatrix} \\begin{pmatrix}\n",
    "    \\sigma_{1}^{-1} & & \\\\\n",
    "    & \\ddots & \\\\\n",
    "    & & \\sigma_{r}^{-1} \\\\\n",
    "  \\end{pmatrix} &c_1 \\\\\n",
    "  0 & 0 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Matrix Norm\n",
    "\n",
    "Matrix Norm Problem. Compute $||A||_2 = \\sup_{v \\neq 0} \\frac{||Av||_2}{||v||_2}$\n",
    "\n",
    "**Lemma** Let $D$ be a nonzero diagonal matrix of size $n \\geq m$. Then $||D||_2 = max\\{|D_{ii}|\\}$\n",
    "\n",
    "**Proof:** Note that $||A||_2 = \\max_{||v||_2 = 1} ||Av||_2$, $||v||_2 = 1$ is a compact set. Thus the maximum exists.\n",
    "\n",
    "Assume $D_{ii}^2 = \\max_j D_{jj}^2$\n",
    "\n",
    "$$||Dv||_2^2 = \\sum_{j=1}^{m}(D_{jj}v_j)^2 \\leq D_{ii}^2\\sum_{j=1}^{m}v_j^2 = D_{ii}^2$$\n",
    "\n",
    "$$||Dv||_2^2 \\leq \\max_j D_{jj}^2$$\n",
    "\n",
    "Let $z_j = \\Big\\{\n",
    "                \\begin{array}{ll}\n",
    "                  0 \\,\\,\\, when j \\neq i\\\\\n",
    "                  \\frac{D_{ii}}{|D_{ii}|} \\,\\,\\, when j = i\n",
    "                \\end{array}$. $||z||_2 = 1$. \n",
    "\n",
    "We have,\n",
    "\n",
    "$$||Dz||_2^2 = \\sum_{j=1}^{m}(D_{jj}v_j)^2 = D_{ii}^2 (\\frac{D_{ii}^2}{|D_{ii}|^2}) = D_{ii}^2$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$|D_{ii}| = ||Dz||_2 \\leq ||D||_2 \\leq |D_{ii}|$$\n",
    "$$\\implies ||D||_2 = \\max \\{|D_{ii}|\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Norm Problem. Compute $||A||_2 = \\sup_{v \\neq 0} \\frac{||Av||_2}{||v||_2}$\n",
    "\n",
    "Now we use SVD to compute $||A||_2$, $A = U\\Sigma V^T$, then:\n",
    "\n",
    "$$\\begin{align*}\n",
    "||A||_2 & = \\max_{||v||_2 = 1} ||U\\Sigma V^Tv||_2 \\\\\n",
    "& = \\max_{||v||_2 = 1} ||\\Sigma V^Tv||_2 \\\\\n",
    "& = \\max_{||z||_2 = 1} ||\\Sigma z||_2 \\\\ \n",
    "& = ||\\Sigma||_2 \\\\\n",
    "& = \\sigma_1\n",
    "\\end{align*}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Low Rank Matrix Approximation\n",
    "$A = \\sum_{i=1}^{r} \\sigma_iu_iv_i^T = U \\Sigma V^T$, we want to find a matrix Y satisfies:\n",
    "\n",
    "$$\\min_{rank(Y) \\leq k} ||A - Y||_F$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW problem:** Show that $||A||_F^2 = \\sum_{i=1}^{n}\\sum_{j=1}^{m}A_{ij}^2$ is orthogonally invariant. i.e:\n",
    "\n",
    "$$||QA||_F = ||A||_F$$\n",
    "$$||AP||_F = ||A||_F$$\n",
    "\n",
    "Where $Q$ and $P$ are orthogonal matrix.\n",
    "\n",
    "**My answer:**\n",
    "\n",
    "$$||A||_F^2 = \\sum_{i=1}^{n}\\sum_{j=1}^{m}A_{ij}^2 = trace(A^TA)$$\n",
    "\n",
    "$$\\begin{align*}||QA||_F  = trace((QA)^TQA) = trace(A^TQ^TQA) = trace(A^TA)=||A||_F^2\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to problem 3. \n",
    "\n",
    "1. Find lower bound, solve it\n",
    "2. Plug in and see if it works\n",
    "\n",
    "Apply the result of HW problem, we get\n",
    "$$||A - Y||_F \\geq | ||A||_F - ||Y||_F | = | ||\\Sigma||_F - ||\\Sigma_Y||_F |$$\n",
    "\n",
    "$$||A - Y||_F^2 = ||U \\Sigma V^T - Y||_F^2 = ||\\Sigma - U^T Y V||_F^2 = \\sum_{i=1}^{n}\\sum_{j=1}^{m} (\\Sigma_{ij} - X_{ij}) = \\sum_{i=1}^{n}\\sum_{j=1, i \\neq j}^{m} (-X_{ij})^2 + \\sum_{i=1}^{n}(\\sigma_i - X_{ii})^2$$\n",
    "\n",
    "where $X = U^T Y V$ Thus, when $X$ is like following we achieve the minimum:\n",
    "\n",
    "$$X \\in R^{n \\times n}, X = \\begin{pmatrix}\n",
    "    \\sigma_{1} & & & &\\\\\n",
    "    & \\ddots & & &\\\\\n",
    "    & & \\sigma_{k} & &\\\\\n",
    "    & & & 0 & \\\\\n",
    "    & & & & \\ddots \\\\\n",
    "    & & & & & 0 \\\\\n",
    "  \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Existence + Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "**Corollary:** rank($A$) = # of non-zero singular values.\n",
    "\n",
    "reference: \n",
    "\n",
    "Some properties of rank\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rank_(linear_algebra)\n",
    "\n",
    "**proof**: Since $U$ and $V$ are of full rank. Then, rank($A$) = rank($U \\Sigma V^T$) = rank($\\Sigma$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corollary:** Let $A, E \\in R^{n \\times m}$, $\\sigma_{max} (\\sigma_{min})$ denote the largest (smallest) sigular value of A. \n",
    "\n",
    "$$\\sigma_{max}(A + E) \\leq \\sigma_{max}(A) + ||E||_2$$\n",
    "$$\\sigma_{min}(A + E) \\geq \\sigma_{min}(A) - ||E||_2$$\n",
    "\n",
    "**proof: HW problem**\n",
    "\n",
    "**My answer:**\n",
    "\n",
    "references:\n",
    "\n",
    "Singular Value Decompostion\n",
    "http://www4.ncsu.edu/~ipsen/REU09/chapter4.pdf\n",
    "\n",
    "http://math.mit.edu/classes/18.095/2016IAP/lec2/SVD_Notes.pdf\n",
    "\n",
    "Matrix norm: \n",
    "http://www4.ncsu.edu/~ipsen/REU09/chapter2.pdf\n",
    "\n",
    "First note that: \n",
    "\n",
    "$$\\sigma_{max}(A) = \\max_{x \\neq 0}\\frac{||Ax||_2}{||x||_2} = ||A||_2$$\n",
    "$$\\sigma_{min}(A) = \\min_{x \\neq 0}\\frac{||Ax||_2}{||x||_2} $$\n",
    "\n",
    "Prove $\\sigma_{max}(A + E) \\leq \\sigma_{max}(A) + ||E||_2$:\n",
    "\n",
    "Given $||E||_2 = \\sigma_{max}(E)$ and given the triangle inequality of matrix norm.  $||A + E||_2 \\leq ||A||_2 + ||E||_2$ $\\implies$ $\\sigma_{max}(A + E) \\leq \\sigma_{max}(A) + ||E||_2$\n",
    "    \n",
    "Prove $\\sigma_{min}(A + E) \\geq \\sigma_{min}(A) - ||E||_2$\n",
    "\n",
    "Let $y$ be a vector so that $\\sigma_{min}(A) = ||Ay||_2$, and $||y||_2 = 1$.\n",
    "\n",
    "$$\\sigma_{min}(A+E) = min_{||x|| = 1}||(A + E)x||_2 \\leq ||(A + E)y||_2 \\leq ||Ay||_2 + ||Ey||_2 = \\sigma_{min}(A) + ||Ey||_2 \\leq \\sigma_{min}(A) + ||E||_2$$\n",
    "\n",
    "Let $z$ be a vector so that $\\sigma_{min}(A+E) = ||(A+E)z||_2$, and $||z||_2 = 1$\n",
    "\n",
    "$$\\sigma_{min}(A) = min_{||x||=1}||Ax||_2 \\leq ||Az||_2 = ||(A+E)z - Ez||_2 \\leq ||(A+E)z||_2 + ||Ez||_2 = ||(A+E)z||_2 + ||Ez||_2 \\leq ||(A+E)z||_2 + ||E||_2$$\n",
    "\n",
    "**remark: Uesful fact**\n",
    "\n",
    "The matrix p-norm are extremely useful because they satisfy the following submultipicative inequality. \n",
    "$$||Ay||_p \\leq ||A||_p||y||_p$$\n",
    "And for $y \\neq 0$ it follows from \n",
    "$$||A||_p = max_{x\\neq 0}\\frac{||Ax||_p}{||x||_p} \\geq \\frac{||Ay||_p}{||y||_p}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corollary:**(Hoffman-Wielandt Inequality)\n",
    "\n",
    "Let $A, E \\in R^{n\\times m}$, $\\sigma_k(\\dot)$ denote $k^{th}$ largest singular value. Let $p = min(m,n)$ then \n",
    "$$\\sum_{k=1}^{p}(\\sigma_k(A+E) - \\sigma_k(A))^2 \\leq ||E||_F^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My Answer:**\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://sites.math.washington.edu/~dumitriu/class16la2.pdf\n",
    "\n",
    "http://djalil.chafai.net/blog/2011/12/03/the-hoffman-wielandt-inequality/\n",
    "\n",
    "https://math.stackexchange.com/questions/1711713/hoffman-wielandt-theorem-proof\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corollary:** : Let $r =$ rank($A$)\n",
    "\n",
    "-1. range($A$) = span($u_1, \\cdots, u_r$)\n",
    "\n",
    "-2. row($A$) = span($v_1, \\cdots, v_r$)\n",
    "\n",
    "-3. null($A$) = span($v_{r+1}, \\cdots, v_m$)\n",
    "\n",
    "-4. null($A$) = span($u_{r+1}, \\cdots, u_n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For (1):**\n",
    "\n",
    "First we prove that range($A$) $\\subseteq$ span($u_1, \\cdots, u_r$)\n",
    "\n",
    "Suppose $b \\in col(A)$ then $\\exists z \\in R^m$\n",
    "\n",
    "Second we prove that range($A$) $\\supseteq$ span($u_1, \\cdots, u_r$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For (3):**\n",
    "\n",
    "First we prove that null($A$) $\\subseteq$ span($v_{r+1}, \\cdots, v_m$)\n",
    "\n",
    "Assume $b \\in$ null($A$), then $Ab = 0$.\n",
    "\n",
    "Because $b \\in R^m$ and $v_1, \\cdots, v_m$ is a base for $R^m$, then $\\exists \\{x_i\\}$ s.t. \n",
    "$b = x_1v_1 + \\cdots + x_rv_r + x_{r+1}v_{r+1} + \\cdots + x_{m}v_m$\n",
    "\n",
    "Assume $b \\notin$ span($v_{r+1}, \\cdots, v_m$), it means that $x_1, \\cdots, x_r$ are not all zero\n",
    "\n",
    "$$Ab= \\sum_{i=1}^{r} \\sigma_i u_i v_i^T b = \\sum_{i=1}^{r}[ \\sigma_i u_i v_i^T (\\sum_{j=1}^{m}x_jv_j)]= \n",
    "\\sum_{i=1}^{r}[ \\sigma_i u_i (\\sum_{j=1}^{m}x_jv_i^Tv_j)] = \\sum_{i=1}^{r} \\sigma_i u_i x_i\n",
    "\\neq 0$$\n",
    "\n",
    "Contradiction!\n",
    "\n",
    "So  $x_1, \\cdots, x_r$ must be all zero, thus $b \\in$ span($v_{r+1}, \\cdots, v_m$)\n",
    "\n",
    "Second we prove that null($A$) $\\supseteq$ span($v_{r+1}, \\cdots, v_m$)\n",
    "\n",
    "if $b \\in$ span($v_{r+1}, \\cdots, v_m$), then $b = \\sum_{j=r+1}^{m}x_jv_j$\n",
    "\n",
    "$$Ab = \\sum_{i=1}^{r} \\sigma_i u_i v_i^T (\\sum_{j=r+1}^{m}x_jv_j) = 0$$\n",
    "\n",
    "Thus $b \\in$ null($A$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**and for (2) and (4)** just do the same job for $A^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
